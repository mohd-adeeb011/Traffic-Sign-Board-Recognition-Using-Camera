{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ab714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f197ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bfd2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Reshape, Activation, Dot\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization, LayerNormalization, Normalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29db225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../archive/Train\"\n",
    "test_folder = \"../archive/Test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split = 0.3,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c618856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "classes = { \n",
    "    0:'Speed limit (20km/h)',\n",
    "    1:'Speed limit (30km/h)', \n",
    "    2:'Speed limit (50km/h)', \n",
    "    3:'Speed limit (60km/h)', \n",
    "    4:'Speed limit (70km/h)', \n",
    "    5:'Speed limit (80km/h)', \n",
    "    6:'End of speed limit (80km/h)', \n",
    "    7:'Speed limit (100km/h)', \n",
    "    8:'Speed limit (120km/h)', \n",
    "    9:'No passing', \n",
    "    10:'No passing veh over 3.5 tons', \n",
    "    11:'Right-of-way at intersection', \n",
    "    12:'Priority road', \n",
    "    13:'Yield', \n",
    "    14:'Stop', \n",
    "    15:'No vehicles', \n",
    "    16:'Veh > 3.5 tons prohibited', \n",
    "    17:'No entry', \n",
    "    18:'General caution', \n",
    "    19:'Dangerous curve left', \n",
    "    20:'Dangerous curve right', \n",
    "    21:'Double curve', \n",
    "    22:'Bumpy road', \n",
    "    23:'Slippery road', \n",
    "    24:'Road narrows on the right', \n",
    "    25:'Road work', \n",
    "    26:'Traffic signals', \n",
    "    27:'Pedestrians', \n",
    "    28:'Children crossing', \n",
    "    29:'Bicycles crossing', \n",
    "    30:'Beware of ice/snow',\n",
    "    31:'Wild animals crossing', \n",
    "    32:'End speed + passing limits', \n",
    "    33:'Turn right ahead', \n",
    "    34:'Turn left ahead', \n",
    "    35:'Ahead only', \n",
    "    36:'Go straight or right', \n",
    "    37:'Go straight or left', \n",
    "    38:'Keep right', \n",
    "    39:'Keep left', \n",
    "    40:'Roundabout mandatory', \n",
    "    41:'End of no passing', \n",
    "    42:'End no passing veh > 3.5 tons'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725a3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "target_size_x = 48\n",
    "target_size_y = 48\n",
    "seed = 123\n",
    "batch_size = 32\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c264e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"../archive/Train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eaa9685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [16:09<00:00, 22.55s/it]\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(len(classes))):         \n",
    "    for imgFile in os.listdir(os.path.join(train_folder, str(i))):\n",
    "        img_path = os.path.join(os.path.join(train_folder, str(i)), imgFile)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (target_size_x,target_size_y))\n",
    "\n",
    "        x_train.append(image/255.0)\n",
    "        y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530d73f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (31367, 48, 48, 3)\n",
      "x_valid.shape (7842, 48, 48, 3)\n",
      "y_train.shape (31367, 43)\n",
      "y_valid.shape (7842, 43)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train, dtype = 'float32')\n",
    "y_train = np.array(y_train, dtype = 'int32')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=43)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
    "print(\"x_train.shape\", x_train.shape)\n",
    "print(\"x_valid.shape\", x_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83f6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow = train_datagen.flow(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")\n",
    "val_flow = test_datagen.flow(\n",
    "    x_val, y_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74a0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRN2D(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Local Contrast Normalisation\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
    "        super(LRN2D, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = X.shape\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = T.sqr(X)\n",
    "        extra_channels = T.alloc(0., b, ch + 2*half_n, r, c)\n",
    "        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i+ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"name\": self.__class__.__name__,\n",
    "                \"alpha\": self.alpha,\n",
    "                \"k\": self.k,\n",
    "                \"beta\": self.beta,\n",
    "                \"n\": self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501f1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_cnn_model():\n",
    "    inputs = layers.Input((target_size_x, target_size_y, 3))\n",
    "    \n",
    "    norm = Normalization(mean=[0.4914, 0.4822, 0.4465], \n",
    "                  variance=[np.square(0.247), \n",
    "                            np.square(0.243), \n",
    "                            np.square(0.261)])(inputs)\n",
    "    \n",
    "    x = Conv2D(filters=200, kernel_size=(7,7), padding='valid', activation='relu', kernel_initializer=\"he_normal\")(norm)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = LRN2D()(x)\n",
    "    \n",
    "    x = Conv2D(filters=250, kernel_size=(4,4), padding='valid', activation='relu', kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = LRN2D()(x)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "    \n",
    "    x = Conv2D(filters=350, kernel_size=(4,4), padding='valid', activation='relu', kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = LRN2D()(x)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    classifier = Dense(43, activation='softmax')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af2b85d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 48, 48, 3)         0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 42, 42, 200)       29600     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 21, 21, 200)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " lrn2d (LRN2D)               (None, 21, 21, 200)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 18, 250)       800250    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 9, 9, 250)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " lrn2d_1 (LRN2D)             (None, 9, 9, 250)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9, 9, 250)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 350)         1400350   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 350)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " lrn2d_2 (LRN2D)             (None, 3, 3, 350)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 3, 350)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3150)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 400)               1260400   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                17243     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3507843 (13.38 MB)\n",
      "Trainable params: 3507843 (13.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = creat_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66df89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, min_lr, max_lr, warmup_steps=4000, alpha=0):\n",
    "        super(CosineDecay, self).__init__()\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_steps = warmup_steps * 10\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = (self.max_lr - self.min_lr) * step / self.warmup_steps + self.min_lr\n",
    "        min_step = tf.math.minimum(step, self.max_steps)\n",
    "        cosine_decay = 0.5 * (1 + tf.math.cos(np.pi * min_step / self.max_steps))\n",
    "        decayed = (1 - self.alpha) * cosine_decay + self.alpha\n",
    "        arg2 = (self.max_lr - self.min_lr) * decayed + self.min_lr\n",
    "        return tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        print(\"\\nEpoch %05d: Current learning rate is %6.4f.\" % (epoch, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07387507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "980/980 [==============================] - 3009s 3s/step - loss: 2.3209 - acc: 0.3572 - top-5-accuracy: 0.6757 - val_loss: 0.8504 - val_acc: 0.7431 - val_top-5-accuracy: 0.9540\n",
      "Epoch 2/30\n",
      "980/980 [==============================] - 2530s 3s/step - loss: 0.9946 - acc: 0.6923 - top-5-accuracy: 0.9383 - val_loss: 0.2224 - val_acc: 0.9397 - val_top-5-accuracy: 0.9971\n",
      "Epoch 3/30\n",
      "980/980 [==============================] - 2501s 3s/step - loss: 0.5426 - acc: 0.8282 - top-5-accuracy: 0.9803 - val_loss: 0.1016 - val_acc: 0.9745 - val_top-5-accuracy: 0.9994\n",
      "Epoch 4/30\n",
      "584/980 [================>.............] - ETA: 18:36 - loss: 0.3798 - acc: 0.8801 - top-5-accuracy: 0.9881"
     ]
    }
   ],
   "source": [
    "epochs = 30   # number of all epochs in training\n",
    "stop_patience = 10   # number of epochs to wait before stopping training if monitored value does not improve\n",
    "batches = int(len(x_train) / batch_size)  # number of training batch to run per epoch\n",
    "\n",
    "warmup_steps = batches * 5\n",
    "learning_rate = CosineDecay(\n",
    "    min_lr=1E-5, max_lr=1E-2, warmup_steps=warmup_steps\n",
    ")\n",
    "    \n",
    "checkpoint = ModelCheckpoint(\n",
    "      filepath='cnn48-{epoch:02d}-{val_acc:.4f}.h5',\n",
    "      save_weights_only=True,\n",
    "      monitor='val_acc',\n",
    "      mode='max',\n",
    "      save_best_only=True,\n",
    "      initial_value_threshold=0.995)\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "      monitor='val_loss', patience=stop_patience, mode='min', restore_best_weights=True)\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "        optimizer, loss=loss_fn,\n",
    "        metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
    "        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")\n",
    "history = model.fit(\n",
    "    x = train_flow,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_flow,\n",
    "    steps_per_epoch=batches,\n",
    "    verbose=1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, earlystop],\n",
    "    validation_steps= None,\n",
    "    shuffle= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3734986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186c07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45dcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d36d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a30633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7c227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
